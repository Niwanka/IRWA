{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niwanka/IRWA/blob/main/CreatingaSearchFunctionsipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nwjD1XwpMtx"
      },
      "source": [
        "**improved search engine begins**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4V6TiTFpig0",
        "outputId": "d8ecb643-b3a6-4e8e-84cf-0e6298c86469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W80nu-G5pVLv"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM4KdllvpVZf",
        "outputId": "a3ff60ab-59fe-44ef-d815-be9fb1aa2bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the English NLP model for NER using SpaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "# Load the pre-trained model for semantic search (Sentence-BERT)\n",
        "sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM9IpcPDn8b2",
        "outputId": "f0a042a8-8d5b-42aa-f6e8-d8fc20693a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.9.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n"
          ]
        }
      ],
      "source": [
        "pip install  pymongo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ippskphdAPKV",
        "outputId": "a6323fdc-f422-4970-8d12-fbab0e15aef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "2E_Te2VzBol3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU0tg3eMKFiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/idf_values.pkl', 'rb') as file:\n",
        "    tfidf_scores = pickle.load(file)\n",
        "\n",
        "def query_expansion(query, model, tfidf_scores, top_n=3):\n",
        "    expanded_terms = set(query.split())\n",
        "    for word in query.split():\n",
        "        if word in model.wv:\n",
        "            similar_words = model.wv.most_similar(word, topn=top_n)\n",
        "\n",
        "\n",
        "            filtered_words = []\n",
        "            for similar_word, similarity_score in similar_words:\n",
        "\n",
        "                if similar_word in tfidf_scores:\n",
        "                    filtered_words.append((similar_word, similarity_score, tfidf_scores[similar_word]))\n",
        "\n",
        "\n",
        "            filtered_words.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "            expanded_terms.update([word_tuple[0] for word_tuple in filtered_words[:top_n]])\n",
        "\n",
        "\n",
        "    expanded_query = \" \".join(expanded_terms)\n",
        "    return expanded_query\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPv2dzgcNWFT"
      },
      "outputs": [],
      "source": [
        "def encode_documents(documents):\n",
        "    return sbert_model.encode(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-cj6i1QL5zh",
        "outputId": "9b3a08eb-4be9-40f2-860b-9e666ade82eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RecipeId': 269099, 'Name': 'Wattleseed Pasta', 'Similarity': 0.7202330125259581}\n",
            "{'RecipeId': 203999, 'Name': 'Drunken Tuscan Pasta', 'Similarity': 0.6921510305001513}\n",
            "{'RecipeId': 164546, 'Name': \"Giada's Spinach and Pancetta Strata Yummy!\", 'Similarity': 0.6760331433778053}\n",
            "{'RecipeId': 520676, 'Name': 'Tagliatella Fatta a Mano Al &ldquo;rag&ugrave; Di Carne&rdquo;', 'Similarity': 0.6575625815014878}\n",
            "{'RecipeId': 312390, 'Name': 'Rigatoni With Tomato, Eggplant, &amp; Red Peppers', 'Similarity': 0.6456224975284106}\n",
            "{'RecipeId': 250664, 'Name': 'Italian Pasta Salad', 'Similarity': 0.6446364743916859}\n",
            "{'RecipeId': 393277, 'Name': \"Eggs for People Who Don't Like Eggs\", 'Similarity': 0.5949323209867314}\n",
            "{'RecipeId': 350683, 'Name': 'Chickpea Pasta With Lemon', 'Similarity': 0.5934182607695508}\n",
            "{'RecipeId': 501218, 'Name': 'PASTa WITH CARROTS, COOKED RISOTTO-STYLE', 'Similarity': 0.5920874398753819}\n",
            "{'RecipeId': 522064, 'Name': 'Zucchini and Trottole Pasta', 'Similarity': 0.5890911992390979}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'RecipeId': 269099,\n",
              "  'Name': 'Wattleseed Pasta',\n",
              "  'Similarity': 0.7202330125259581},\n",
              " {'RecipeId': 203999,\n",
              "  'Name': 'Drunken Tuscan Pasta',\n",
              "  'Similarity': 0.6921510305001513},\n",
              " {'RecipeId': 164546,\n",
              "  'Name': \"Giada's Spinach and Pancetta Strata Yummy!\",\n",
              "  'Similarity': 0.6760331433778053},\n",
              " {'RecipeId': 520676,\n",
              "  'Name': 'Tagliatella Fatta a Mano Al &ldquo;rag&ugrave; Di Carne&rdquo;',\n",
              "  'Similarity': 0.6575625815014878},\n",
              " {'RecipeId': 312390,\n",
              "  'Name': 'Rigatoni With Tomato, Eggplant, &amp; Red Peppers',\n",
              "  'Similarity': 0.6456224975284106},\n",
              " {'RecipeId': 250664,\n",
              "  'Name': 'Italian Pasta Salad',\n",
              "  'Similarity': 0.6446364743916859},\n",
              " {'RecipeId': 393277,\n",
              "  'Name': \"Eggs for People Who Don't Like Eggs\",\n",
              "  'Similarity': 0.5949323209867314},\n",
              " {'RecipeId': 350683,\n",
              "  'Name': 'Chickpea Pasta With Lemon',\n",
              "  'Similarity': 0.5934182607695508},\n",
              " {'RecipeId': 501218,\n",
              "  'Name': 'PASTa WITH CARROTS, COOKED RISOTTO-STYLE',\n",
              "  'Similarity': 0.5920874398753819},\n",
              " {'RecipeId': 522064,\n",
              "  'Name': 'Zucchini and Trottole Pasta',\n",
              "  'Similarity': 0.5890911992390979}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "from pymongo import MongoClient\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Establish MongoDB connection and define the collection before defining the function\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\n",
        "\n",
        "# Create a text index on the 'Name' field\n",
        "collection.create_index([(\"text\", \"text\")])\n",
        "\n",
        "\n",
        "def search_with_text_filter(query, top_n=10):\n",
        "    # Perform a text search on the collection\n",
        "    filtered_docs = list(collection.find(\n",
        "        {\"$text\": {\"$search\": query}},\n",
        "        {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1, \"score\": {\"$meta\": \"textScore\"}}\n",
        "    ).sort([(\"score\", {\"$meta\": \"textScore\"})]).limit(50))\n",
        "\n",
        "    # Check if any documents were found\n",
        "    if not filtered_docs:\n",
        "        print(\"No documents found using text search.\")\n",
        "        return []\n",
        "\n",
        "    # Extract embeddings and other details\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in filtered_docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in filtered_docs]\n",
        "    doc_names = [doc['Name'] for doc in filtered_docs]\n",
        "\n",
        "    # Get the query embedding\n",
        "    query_embedding = encode_documents([query])[0]  # Assuming encode_documents is defined elsewhere\n",
        "\n",
        "    # Calculate cosine similarity between query embedding and document embeddings\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Get the top N results based on similarity\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    # Prepare the results\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        result = {\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        }\n",
        "        print(result)\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Call the function after defining the collection\n",
        "query = \"Italian pasta with pancetta and eggs\"\n",
        "search_with_text_filter(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7du0n-YoYYb9",
        "outputId": "53fd84ff-fc7f-4854-cdb0-71d24b30a415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Query: chocolate cake\n",
            "\n",
            "Results for the Original Query:\n",
            "RecipeId: 132143, Name: Real Chocolate Cake\n",
            "RecipeId: 103165, Name: Molten Chocolate Cakes\n",
            "RecipeId: 317926, Name: Fudgy Peanut Butter Swirl Cake\n",
            "RecipeId: 170642, Name: Triple the Chocolate Fancy Cakes\n",
            "RecipeId: 160433, Name: All Chocolate Boston Cream Pie\n",
            "RecipeId: 188513, Name: Soft-Centered Warm Chocolate Cakes\n",
            "RecipeId: 466927, Name: Quick &amp; Easy Chocolate Peanut Butter Cake\n",
            "RecipeId: 343794, Name: Chocolate Black-Out Cake With Ganache Drizzle -Jacques Torres\n",
            "RecipeId: 419871, Name: Piece of Cake to Make Chocolate Cake\n",
            "RecipeId: 391316, Name: Rocky Road Chocolate Cake (Crock-Pot)\n",
            "RecipeId: 345918, Name: Chocolate Maraschino Cherry Cake\n",
            "RecipeId: 16944, Name: Ultimate Chocolate Cake\n",
            "RecipeId: 34947, Name: Chocolate Cake With Chocolate Sauce\n",
            "RecipeId: 200024, Name: Raspberry and Coconut Snowflake Cake\n",
            "RecipeId: 473358, Name: Chocolate Almond-Coconut Cake (Almond Joy Cake)\n",
            "RecipeId: 327716, Name: Chocolate Banana Bread\n",
            "RecipeId: 49613, Name: The Best Chocolate Cake (Really!)\n",
            "RecipeId: 480973, Name: Nutella Chocolate Chip Cookie Icebox Cake\n",
            "RecipeId: 42469, Name: Chocolate Espresso Cake\n",
            "RecipeId: 2496, Name: Dark Chocolate Cake\n",
            "RecipeId: 132333, Name: Peanut Butter Dandy Cake (Chocolate Cake)\n",
            "RecipeId: 63073, Name: Heavenly Chocolate Raspberry Bundt Cake\n",
            "RecipeId: 538791, Name: Ding Dong Cake\n",
            "RecipeId: 17795, Name: Chocolate Cherry Cake\n",
            "RecipeId: 187120, Name: Chocolate Chip Streusel Coffee Cake\n",
            "RecipeId: 55847, Name: Chocolate Eclair Cake\n",
            "RecipeId: 52195, Name: Quick Black Forest Cake\n",
            "RecipeId: 476979, Name: Bestest Chocolate Cake Ever\n",
            "RecipeId: 10154, Name: Chocolate Chip Date Cake\n",
            "RecipeId: 320662, Name: White Chocolate Cream Cake\n",
            "RecipeId: 230608, Name: Chocolate Stout Cake\n",
            "RecipeId: 54959, Name: Chocolate Pudding Cake\n",
            "RecipeId: 407387, Name: Mini Chocolate Cakes\n",
            "RecipeId: 114012, Name: Chocolate Espresso Cake (flourless)\n",
            "RecipeId: 278928, Name: Chocolate Mousse Cake\n",
            "RecipeId: 305870, Name: Bailey's Brownie Trifle\n",
            "RecipeId: 529800, Name: Soya Chocolate Cake Batter Ice Cream With Oreos and Chocolate Sa\n",
            "RecipeId: 14698, Name: Chocolate Mousse Cake\n",
            "RecipeId: 322101, Name: Chocolate Caramel Cake\n",
            "RecipeId: 118556, Name: Chocolate Cherry Skillet Cake\n",
            "RecipeId: 209720, Name: Mary's German Chocolate Cake Icing\n",
            "RecipeId: 367674, Name: Low Cost Chocolate Cake\n",
            "RecipeId: 293931, Name: World's Best Chocolate Cake\n",
            "RecipeId: 252323, Name: Chocolate Cake\n",
            "RecipeId: 385936, Name: Chocolate Pound Cake\n",
            "RecipeId: 78090, Name: Better Than Sex Cake\n",
            "RecipeId: 516422, Name: Dark Chocolate Crunch Ice Cream Sandwich Cake\n",
            "RecipeId: 488929, Name: Chocolate Cannoli Cake Roll\n",
            "RecipeId: 532351, Name: Molten Caramel Cakes\n",
            "RecipeId: 285719, Name: Sour Cream Chocolate Swirl Coffee Cake\n",
            "\n",
            "Expanded Query: cheesecake cake bar brownie chocolate fudge cupcake\n",
            "\n",
            "Results for the Expanded Query:\n",
            "RecipeId: 358129, Name: Peanut Butter and Chocolate Cheesecake Brownies\n",
            "RecipeId: 64806, Name: Mocha Chocolate Chip Cheesecake Bars\n",
            "RecipeId: 305870, Name: Bailey's Brownie Trifle\n",
            "RecipeId: 45228, Name: Ooey Gooey Brownies\n",
            "RecipeId: 23298, Name: German Chocolate Brownies\n",
            "RecipeId: 329775, Name: Devil's Food Cheesecake\n",
            "RecipeId: 97790, Name: German Chocolate Brownies (no Cake Mix Required)\n",
            "RecipeId: 182146, Name: Chewy Chocolate Chip-Nut Bars\n",
            "RecipeId: 132607, Name: Blonde Brownies\n",
            "RecipeId: 382132, Name: Joe Bars (Chocolate Granola Bars)\n",
            "RecipeId: 2496, Name: Dark Chocolate Cake\n",
            "RecipeId: 35853, Name: Chocolate Brownies\n",
            "RecipeId: 318949, Name: Fudge Brownies\n",
            "RecipeId: 83806, Name: Oatmeal Chocolate Chip Bars\n",
            "RecipeId: 413977, Name: Cranberry Cheesecake Bars\n",
            "RecipeId: 279972, Name: Irish Mint Brownies\n",
            "RecipeId: 281488, Name: Cinnamon Mocha Fudge Bars (Cookie Mix)\n",
            "RecipeId: 63100, Name: Chocolate-Fudge Brownies\n",
            "RecipeId: 54959, Name: Chocolate Pudding Cake\n",
            "RecipeId: 214537, Name: Pina Colada Cheesecake Bars\n",
            "RecipeId: 408787, Name: Copycat Cracker Barrel 40th Anniversary Double Fudge Cola Cake\n",
            "RecipeId: 204378, Name: Orange &amp; Chocolate  Fantasy Bar\n",
            "RecipeId: 316746, Name: Chocolate Fudge Drops With Frosting\n",
            "RecipeId: 483028, Name: Chocolate Delight Fudge Cookies\n",
            "RecipeId: 46452, Name: Mike's Favorite Fudge Brownies\n",
            "RecipeId: 157060, Name: Chunky  Chocolate Peanut Butter Bars\n",
            "RecipeId: 309109, Name: Honey and Carob Brownies\n",
            "RecipeId: 211609, Name: Cointreau Blondies\n",
            "RecipeId: 9095, Name: Mars Bar Slice\n",
            "RecipeId: 395418, Name: Turtle Bars\n",
            "RecipeId: 132143, Name: Real Chocolate Cake\n",
            "RecipeId: 74782, Name: Brown Stuff (Chocolate Slice) - Don't Be Put off by the Name !\n",
            "RecipeId: 437657, Name: Homemade Granola Bars\n",
            "RecipeId: 103165, Name: Molten Chocolate Cakes\n",
            "RecipeId: 24460, Name: Caribbean Brownies\n",
            "RecipeId: 6891, Name: Caramel Brownies\n",
            "RecipeId: 28022, Name: Caramel-Oatmeal Chewy Bars\n",
            "RecipeId: 217092, Name: Double Frosted Peanut Butter Bars\n",
            "RecipeId: 7782, Name: Sugar Free Brownies\n",
            "RecipeId: 317926, Name: Fudgy Peanut Butter Swirl Cake\n",
            "RecipeId: 200321, Name: White Chocolate Peanut Butter Cookies\n",
            "RecipeId: 89836, Name: Dream Bars\n",
            "RecipeId: 331521, Name: Chocolate Malt Cheesecake\n",
            "RecipeId: 99792, Name: Oatmeal Raisin Chocolate Chip Bars\n",
            "RecipeId: 170642, Name: Triple the Chocolate Fancy Cakes\n",
            "RecipeId: 160433, Name: All Chocolate Boston Cream Pie\n",
            "RecipeId: 270596, Name: Fiber One Crunchy Fudge Cookies\n",
            "RecipeId: 161224, Name: Applesauce Chocolate Chip Brownies\n",
            "RecipeId: 195800, Name: Brownie Caramel Walnut Bars\n",
            "RecipeId: 182542, Name: Cookie Dough Master Recipe\n",
            "\n",
            "Calculating Cosine Similarity with the Expanded Query...\n",
            "{'RecipeId': 103165, 'Name': 'Molten Chocolate Cakes', 'Similarity': 0.6837532068522104}\n",
            "{'RecipeId': 54959, 'Name': 'Chocolate Pudding Cake', 'Similarity': 0.6766146332247656}\n",
            "{'RecipeId': 97790, 'Name': 'German Chocolate Brownies (no Cake Mix Required)', 'Similarity': 0.6337265256924391}\n",
            "{'RecipeId': 331521, 'Name': 'Chocolate Malt Cheesecake', 'Similarity': 0.6310958958724624}\n",
            "{'RecipeId': 160433, 'Name': 'All Chocolate Boston Cream Pie', 'Similarity': 0.6296384717441132}\n",
            "{'RecipeId': 45228, 'Name': 'Ooey Gooey Brownies', 'Similarity': 0.626651032223426}\n",
            "{'RecipeId': 329775, 'Name': \"Devil's Food Cheesecake\", 'Similarity': 0.6233423481279062}\n",
            "{'RecipeId': 305870, 'Name': \"Bailey's Brownie Trifle\", 'Similarity': 0.6226978355923758}\n",
            "{'RecipeId': 170642, 'Name': 'Triple the Chocolate Fancy Cakes', 'Similarity': 0.6206329478886619}\n",
            "{'RecipeId': 270596, 'Name': 'Fiber One Crunchy Fudge Cookies', 'Similarity': 0.6168946102914495}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'RecipeId': 103165,\n",
              "  'Name': 'Molten Chocolate Cakes',\n",
              "  'Similarity': 0.6837532068522104},\n",
              " {'RecipeId': 54959,\n",
              "  'Name': 'Chocolate Pudding Cake',\n",
              "  'Similarity': 0.6766146332247656},\n",
              " {'RecipeId': 97790,\n",
              "  'Name': 'German Chocolate Brownies (no Cake Mix Required)',\n",
              "  'Similarity': 0.6337265256924391},\n",
              " {'RecipeId': 331521,\n",
              "  'Name': 'Chocolate Malt Cheesecake',\n",
              "  'Similarity': 0.6310958958724624},\n",
              " {'RecipeId': 160433,\n",
              "  'Name': 'All Chocolate Boston Cream Pie',\n",
              "  'Similarity': 0.6296384717441132},\n",
              " {'RecipeId': 45228,\n",
              "  'Name': 'Ooey Gooey Brownies',\n",
              "  'Similarity': 0.626651032223426},\n",
              " {'RecipeId': 329775,\n",
              "  'Name': \"Devil's Food Cheesecake\",\n",
              "  'Similarity': 0.6233423481279062},\n",
              " {'RecipeId': 305870,\n",
              "  'Name': \"Bailey's Brownie Trifle\",\n",
              "  'Similarity': 0.6226978355923758},\n",
              " {'RecipeId': 170642,\n",
              "  'Name': 'Triple the Chocolate Fancy Cakes',\n",
              "  'Similarity': 0.6206329478886619},\n",
              " {'RecipeId': 270596,\n",
              "  'Name': 'Fiber One Crunchy Fudge Cookies',\n",
              "  'Similarity': 0.6168946102914495}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import pickle\n",
        "from textblob import TextBlob  # Library for spell correction\n",
        "from pymongo import MongoClient\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load TF-IDF values for query expansion\n",
        "with open('/content/drive/MyDrive/idf_values.pkl', 'rb') as file:\n",
        "    tfidf_scores = pickle.load(file)\n",
        "\n",
        "# Define the query expansion function\n",
        "def query_expansion(query, model, tfidf_scores, top_n=3):\n",
        "    expanded_terms = set(query.split())\n",
        "    for word in query.split():\n",
        "        if word in model.wv:\n",
        "            # Get top N similar words for the given word\n",
        "            similar_words = model.wv.most_similar(word, topn=top_n)\n",
        "\n",
        "            filtered_words = []\n",
        "            for similar_word, similarity_score in similar_words:\n",
        "                # Check if the similar word has a corresponding TF-IDF score\n",
        "                if similar_word in tfidf_scores:\n",
        "                    filtered_words.append((similar_word, similarity_score, tfidf_scores[similar_word]))\n",
        "\n",
        "            # Sort by TF-IDF score to retain the most relevant similar words\n",
        "            filtered_words.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "            # Update the expanded terms with the top similar words\n",
        "            expanded_terms.update([word_tuple[0] for word_tuple in filtered_words[:top_n]])\n",
        "\n",
        "    expanded_query = \" \".join(expanded_terms)\n",
        "    return expanded_query\n",
        "\n",
        "# Function for spell correction using TextBlob\n",
        "def spell_correct(query):\n",
        "    corrected_query = str(TextBlob(query).correct())\n",
        "    return corrected_query\n",
        "\n",
        "# MongoDB connection setup\n",
        "\n",
        "\n",
        "# Create a text index on the 'Name' field if not already created\n",
        "collection.create_index([(\"text\", \"text\")])\n",
        "\n",
        "# Function to search and list items using a query with and without expansion\n",
        "def search_with_text_filter(query, model, tfidf_scores, top_n=10):\n",
        "    # Step 1: Correct any spelling mistakes in the query\n",
        "    corrected_query = spell_correct(query)\n",
        "    print(f\"Corrected Query: {corrected_query}\")\n",
        "\n",
        "    # Step 2: Perform text search on the collection using the corrected query\n",
        "    print(\"\\nResults for the Original Query:\")\n",
        "    original_results = list(collection.find(\n",
        "        {\"$text\": {\"$search\": corrected_query}},\n",
        "        {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1, \"score\": {\"$meta\": \"textScore\"}}\n",
        "    ).sort([(\"score\", {\"$meta\": \"textScore\"})]).limit(50))\n",
        "\n",
        "    # Display original query results\n",
        "    for doc in original_results:\n",
        "        print(f\"RecipeId: {doc['RecipeId']}, Name: {doc['Name']}\")\n",
        "\n",
        "    # Step 3: Perform query expansion\n",
        "    expanded_query = query_expansion(corrected_query, model, tfidf_scores, top_n=3)\n",
        "    print(f\"\\nExpanded Query: {expanded_query}\")\n",
        "\n",
        "    # Step 4: Perform text search on the collection using the expanded query\n",
        "    print(\"\\nResults for the Expanded Query:\")\n",
        "    expanded_results = list(collection.find(\n",
        "        {\"$text\": {\"$search\": expanded_query}},\n",
        "        {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1, \"score\": {\"$meta\": \"textScore\"}}\n",
        "    ).sort([(\"score\", {\"$meta\": \"textScore\"})]).limit(50))\n",
        "\n",
        "    # Display expanded query results\n",
        "    for doc in expanded_results:\n",
        "        print(f\"RecipeId: {doc['RecipeId']}, Name: {doc['Name']}\")\n",
        "\n",
        "    # Step 5: If there are embeddings in the results, perform cosine similarity-based ranking\n",
        "    if expanded_results:\n",
        "        print(\"\\nCalculating Cosine Similarity with the Expanded Query...\")\n",
        "        # Extract embeddings and other details\n",
        "        doc_embeddings = np.array([doc['encoded_vector'] for doc in expanded_results])\n",
        "        doc_ids = [doc['RecipeId'] for doc in expanded_results]\n",
        "        doc_names = [doc['Name'] for doc in expanded_results]\n",
        "\n",
        "        # Get the query embedding using your existing encoding function\n",
        "        query_embedding = encode_documents([expanded_query])[0]  # Assuming encode_documents is defined elsewhere\n",
        "\n",
        "        # Calculate cosine similarity between query embedding and document embeddings\n",
        "        similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "        # Get the top N results based on similarity\n",
        "        top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "        # Prepare the results\n",
        "        similarity_results = []\n",
        "        for idx in top_n_indices:\n",
        "            result = {\n",
        "                'RecipeId': doc_ids[idx],\n",
        "                'Name': doc_names[idx],\n",
        "                'Similarity': similarities[idx]\n",
        "            }\n",
        "            print(result)\n",
        "            similarity_results.append(result)\n",
        "\n",
        "        return similarity_results\n",
        "\n",
        "model = Word2Vec.load('/content/drive/MyDrive/word2vec_model.pkl')\n",
        "\n",
        "query = \"chocolate cake\"  # Replace with your actual search query\n",
        "\n",
        "# Call the search function\n",
        "search_with_text_filter(query, model, tfidf_scores, top_n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XY67qOfMQhn"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pymongo import MongoClient\n",
        "\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\n",
        "\n",
        "def create_clusters(n_clusters=10):\n",
        "    # Retrieve documents with RecipeId and encoded_vector from the collection\n",
        "    documents = list(collection.find({}, {\"RecipeId\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    # Create a numpy array of encoded vectors\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in documents])\n",
        "\n",
        "    # Fit KMeans clustering model\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(doc_embeddings)\n",
        "\n",
        "    # Update the cluster label for each document in the collection\n",
        "    for i, doc in enumerate(documents):\n",
        "        collection.update_one(\n",
        "            {\"_id\": doc[\"_id\"]},\n",
        "            {\"$set\": {\"cluster\": int(kmeans.labels_[i])}}\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTD3hLNqIMGO"
      },
      "outputs": [],
      "source": [
        "def search_using_clusters(query, top_n=10):\n",
        "    # Encode the query to get its vector representation\n",
        "    query_embedding = encode_documents([query])[0]\n",
        "\n",
        "    # Retrieve documents with encoded_vector and cluster from the collection\n",
        "    documents = list(collection.find({}, {\"encoded_vector\": 1, \"cluster\": 1}))\n",
        "\n",
        "    # Create numpy arrays for document embeddings and clusters\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in documents])\n",
        "    clusters = np.array([int(doc['cluster']) for doc in documents])  # Convert clusters to Python int\n",
        "\n",
        "    # Calculate cosine similarities between the query and document embeddings\n",
        "    cluster_distances = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Determine the closest cluster based on the max similarity\n",
        "    closest_cluster = clusters[np.argmax(cluster_distances)]\n",
        "\n",
        "    # Retrieve documents from the closest cluster\n",
        "    filtered_docs = list(collection.find({\"cluster\": int(closest_cluster)}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    # Create numpy arrays for the filtered document embeddings and IDs\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in filtered_docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in filtered_docs]\n",
        "    doc_names = [doc['Name'] for doc in filtered_docs]\n",
        "\n",
        "    # Calculate similarities for the top N results\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    # Collect and print results\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        result = {\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysGe_xBrIphw",
        "outputId": "6bb73ff7-0ba1-4ce8-8add-444c45f6d613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.9.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n"
          ]
        }
      ],
      "source": [
        "pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnzyW1NsGswf",
        "outputId": "8872f133-529a-4620-ddea-50b393575941"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'RecipeId': 379868,\n",
              "  'Name': 'Roasted Tomato and Shrimp Pasta',\n",
              "  'Similarity': 0.7327936594871476},\n",
              " {'RecipeId': 176435,\n",
              "  'Name': \"Pasta Puttanesca ( the Madame's Pasta )\",\n",
              "  'Similarity': 0.7270963192904074},\n",
              " {'RecipeId': 269099,\n",
              "  'Name': 'Wattleseed Pasta',\n",
              "  'Similarity': 0.7249029185305045},\n",
              " {'RecipeId': 170211,\n",
              "  'Name': 'Savory Summer Pasta Salad',\n",
              "  'Similarity': 0.7246296998024855},\n",
              " {'RecipeId': 250664,\n",
              "  'Name': 'Italian Pasta Salad',\n",
              "  'Similarity': 0.7201932765245769},\n",
              " {'RecipeId': 275554,\n",
              "  'Name': 'Pasta With Chicken and Squash',\n",
              "  'Similarity': 0.7138433335132078},\n",
              " {'RecipeId': 120095,\n",
              "  'Name': 'Mizithra Browned Buttered Pasta',\n",
              "  'Similarity': 0.7092546480718479},\n",
              " {'RecipeId': 263553,\n",
              "  'Name': 'Pasta With Potatoes and Herbs',\n",
              "  'Similarity': 0.7066315511465511},\n",
              " {'RecipeId': 431225,\n",
              "  'Name': 'Killer Pasta Alfredo(Esque) With Chicken &amp; Bacon',\n",
              "  'Similarity': 0.7046617537363333},\n",
              " {'RecipeId': 295183,\n",
              "  'Name': 'Shrimp and Angel Hair Pasta',\n",
              "  'Similarity': 0.7037909506546474}]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pymongo import MongoClient\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\n",
        "# Example query for searching\n",
        "query = \"Delicious pasta\"\n",
        "search_using_clusters(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpbNZGNA0Tmz",
        "outputId": "11e372d7-ca73-4e98-9af7-0f8902ecf14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RecipeId': 269099, 'Name': 'Wattleseed Pasta', 'Similarity': 0.7202330125259581}\n",
            "{'RecipeId': 176435, 'Name': \"Pasta Puttanesca ( the Madame's Pasta )\", 'Similarity': 0.7100361742691912}\n",
            "{'RecipeId': 203999, 'Name': 'Drunken Tuscan Pasta', 'Similarity': 0.6921510305001513}\n",
            "{'RecipeId': 275554, 'Name': 'Pasta With Chicken and Squash', 'Similarity': 0.6903238633746664}\n",
            "{'RecipeId': 120095, 'Name': 'Mizithra Browned Buttered Pasta', 'Similarity': 0.6868085141883233}\n",
            "{'RecipeId': 379868, 'Name': 'Roasted Tomato and Shrimp Pasta', 'Similarity': 0.6799918370189806}\n",
            "{'RecipeId': 164546, 'Name': \"Giada's Spinach and Pancetta Strata Yummy!\", 'Similarity': 0.6760331433778053}\n",
            "{'RecipeId': 411853, 'Name': 'Delicious Pesto Cream Sauce', 'Similarity': 0.6742843301587211}\n",
            "{'RecipeId': 337285, 'Name': 'Linguine Alla Vongole', 'Similarity': 0.6705833703062491}\n",
            "{'RecipeId': 172511, 'Name': 'Egg Noodles With Brown Butter and Feta', 'Similarity': 0.6638602458848739}\n"
          ]
        }
      ],
      "source": [
        "from pymongo import MongoClient\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Establish MongoDB connection\n",
        "\"\"\"client = MongoClient(\"mongodb+srv://sriharansaravanans:s1EW50F5k9Oyt8xi@cluster0.zr38q.mongodb.net/\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\"\"\"\n",
        "\n",
        "# Load a pre-trained model for generating query embeddings\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# Retrieve document embeddings from MongoDB and perform cosine similarity in Python\n",
        "def search_with_cosine_similarity(query_embedding, top_n=10):\n",
        "    # Retrieve all documents with their embeddings from MongoDB\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    # Extract embeddings and other details\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    # Calculate cosine similarity between query embedding and document embeddings\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Get the top N results based on similarity\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    # Prepare the results\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        result = {\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        }\n",
        "        print(result)\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Generate query embedding\n",
        "query_embedding = encode_documents([\"Italian pasta with pancetta and eggs\"])[0]\n",
        "\n",
        "# Perform the similarity search\n",
        "results = search_with_cosine_similarity(query_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0qcpZCGTiMd",
        "outputId": "de3b286e-b045-49d2-824a-0c9abdfc3d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RecipeId': 269099, 'Name': 'Wattleseed Pasta', 'Similarity': 0.7202330125259581}\n",
            "{'RecipeId': 176435, 'Name': \"Pasta Puttanesca ( the Madame's Pasta )\", 'Similarity': 0.7100361742691912}\n",
            "{'RecipeId': 203999, 'Name': 'Drunken Tuscan Pasta', 'Similarity': 0.6921510305001513}\n",
            "{'RecipeId': 275554, 'Name': 'Pasta With Chicken and Squash', 'Similarity': 0.6903238633746664}\n",
            "{'RecipeId': 120095, 'Name': 'Mizithra Browned Buttered Pasta', 'Similarity': 0.6868085141883233}\n",
            "{'RecipeId': 379868, 'Name': 'Roasted Tomato and Shrimp Pasta', 'Similarity': 0.6799918370189806}\n",
            "{'RecipeId': 164546, 'Name': \"Giada's Spinach and Pancetta Strata Yummy!\", 'Similarity': 0.6760331433778053}\n",
            "{'RecipeId': 411853, 'Name': 'Delicious Pesto Cream Sauce', 'Similarity': 0.6742843301587211}\n",
            "{'RecipeId': 337285, 'Name': 'Linguine Alla Vongole', 'Similarity': 0.6705833703062491}\n",
            "{'RecipeId': 172511, 'Name': 'Egg Noodles With Brown Butter and Feta', 'Similarity': 0.6638602458848739}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "def search_with_nearest_neighbors(query_embedding, top_n=10):\n",
        "    # Retrieve all documents with their embeddings from MongoDB\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    # Check if documents are found\n",
        "    if not docs:\n",
        "        print(\"No documents found in the database.\")\n",
        "        return []\n",
        "\n",
        "    # Extract embeddings and other details\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    # Initialize the NearestNeighbors model for cosine similarity\n",
        "    # Use 'metric=cosine' for calculating cosine similarity\n",
        "    neigh = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
        "    neigh.fit(doc_embeddings)\n",
        "\n",
        "    # Find the nearest neighbors based on cosine similarity\n",
        "    distances, indices = neigh.kneighbors([query_embedding], n_neighbors=top_n)\n",
        "\n",
        "    # Prepare the results based on nearest neighbor indices\n",
        "    results = []\n",
        "    for idx, distance in zip(indices[0], distances[0]):\n",
        "        result = {\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': 1 - distance  # Similarity is (1 - cosine distance)\n",
        "        }\n",
        "        print(result)\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "# Generate query embedding\n",
        "query_embedding = encode_documents([\"Italian pasta with pancetta and eggs\"])[0]\n",
        "\n",
        "# Perform the similarity search using nearest neighbors\n",
        "results = search_with_nearest_neighbors(query_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# MongoDB client setup\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client['searchEngine']\n",
        "collection = db['pdf_files']\n",
        "\n",
        "def search_pdf(query):\n",
        "    # Create embedding for the search query\n",
        "    query_embedding = model.encode([query])[0]\n",
        "\n",
        "    # Retrieve all stored PDF embeddings from MongoDB\n",
        "    pdf_data = list(collection.find({}))\n",
        "    pdf_embeddings = [np.array(pdf['embedding']) for pdf in pdf_data]\n",
        "\n",
        "    # Calculate cosine similarities between query and stored embeddings\n",
        "    similarities = cosine_similarity([query_embedding], pdf_embeddings)[0]\n",
        "\n",
        "    # Get the indices of the top ten highest similarity scores\n",
        "    top_indices = np.argsort(similarities)[-10:][::-1]\n",
        "\n",
        "    # Collect the names and download links of the top ten PDFs\n",
        "    top_pdfs = []\n",
        "    for index in top_indices:\n",
        "        top_pdfs.append({\n",
        "            'name': pdf_data[index]['file_name'],  # Assuming 'name' field exists in your PDF data\n",
        "            'download_link': pdf_data[index]['download_link']\n",
        "        })\n",
        "\n",
        "    return top_pdfs\n",
        "\n",
        "# Example usage: Search for a PDF\n",
        "query = \"Quick and easy recipes\"\n",
        "top_ten_pdfs = search_pdf(query)\n",
        "\n",
        "# Display the results\n",
        "for pdf in top_ten_pdfs:\n",
        "    print(f\"Name: {pdf['name']}, Download Link: {pdf['download_link']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuU9DG0zN7zm",
        "outputId": "1e59210b-514e-4846-ac31-56cd93ffbe08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Easy_recipes.pdf, Download Link: https://drive.google.com/uc?id=1dZA-OVeYW-8aYT30a6UHoXATyUdiShNP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from pymongo import MongoClient\n",
        "from textblob import TextBlob\n",
        "import pickle\n",
        "\n",
        "# MongoDB client setup\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\n",
        "\n",
        "# Load pre-trained model for generating query embeddings\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Load TF-IDF scores for query expansion\n",
        "with open('/content/drive/MyDrive/idf_values.pkl', 'rb') as file:\n",
        "    tfidf_scores = pickle.load(file)\n",
        "\n",
        "# Function for spell correction\n",
        "def spell_correct(query):\n",
        "    corrected_query = str(TextBlob(query).correct())\n",
        "    return corrected_query\n",
        "\n",
        "# Search function using cosine similarity\n",
        "def search_with_cosine_similarity(query_embedding, top_n=10):\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    if not docs:\n",
        "        return []\n",
        "\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        results.append({\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Search function using Nearest Neighbors\n",
        "def search_with_nearest_neighbors(query_embedding, top_n=10):\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    if not docs:\n",
        "        return []\n",
        "\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    neigh = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
        "    neigh.fit(doc_embeddings)\n",
        "    distances, indices = neigh.kneighbors([query_embedding], n_neighbors=top_n)\n",
        "\n",
        "    results = []\n",
        "    for idx, distance in zip(indices[0], distances[0]):\n",
        "        results.append({\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': 1 - distance\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Combined search and ranking function\n",
        "def search_and_rank(query, top_n=20):\n",
        "    # Step 1: Encode the original query\n",
        "    original_query_embedding = model.encode([query])[0]\n",
        "\n",
        "    # Step 2: Perform normal search with cosine similarity and nearest neighbors\n",
        "    cosine_results = search_with_cosine_similarity(original_query_embedding, top_n)\n",
        "    nn_results = search_with_nearest_neighbors(original_query_embedding, top_n)\n",
        "\n",
        "    # Merge both result sets (union of results)\n",
        "    all_results = {result['RecipeId']: result for result in cosine_results + nn_results}\n",
        "\n",
        "    # Step 3: Apply spell check\n",
        "    corrected_query = spell_correct(query)\n",
        "\n",
        "    # Step 4: Encode the corrected query\n",
        "    corrected_query_embedding = model.encode([corrected_query])[0]\n",
        "\n",
        "    # Step 5: Perform search with the corrected query\n",
        "    corrected_cosine_results = search_with_cosine_similarity(corrected_query_embedding, top_n)\n",
        "    corrected_nn_results = search_with_nearest_neighbors(corrected_query_embedding, top_n)\n",
        "\n",
        "    # Merge expanded results with original results\n",
        "    expanded_results = {result['RecipeId']: result for result in corrected_cosine_results + corrected_nn_results}\n",
        "    all_results.update(expanded_results)\n",
        "\n",
        "    # Step 6: Sort results by cosine similarity (or combined similarity)\n",
        "    sorted_results = sorted(all_results.values(), key=lambda x: x['Similarity'], reverse=True)\n",
        "\n",
        "    # Return top results\n",
        "    return sorted_results[:top_n]\n",
        "\n",
        "# Example usage\n",
        "query = \"Italian pasta with pancetta and eggs\"\n",
        "top_ten_results = search_and_rank(query)\n",
        "\n",
        "# Display the results\n",
        "for result in top_ten_results:\n",
        "    print(f\"RecipeId: {result['RecipeId']}, Name: {result['Name']}, Similarity: {result['Similarity']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RjjQb9zP-nD",
        "outputId": "317b3a7d-9a17-49ef-9d50-1a2d4e28f912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecipeId: 269099, Name: Wattleseed Pasta, Similarity: 0.7202330125259581\n",
            "RecipeId: 176435, Name: Pasta Puttanesca ( the Madame's Pasta ), Similarity: 0.7100361742691912\n",
            "RecipeId: 203999, Name: Drunken Tuscan Pasta, Similarity: 0.6921510305001513\n",
            "RecipeId: 275554, Name: Pasta With Chicken and Squash, Similarity: 0.6903238633746664\n",
            "RecipeId: 120095, Name: Mizithra Browned Buttered Pasta, Similarity: 0.6868085141883233\n",
            "RecipeId: 379868, Name: Roasted Tomato and Shrimp Pasta, Similarity: 0.6799918370189806\n",
            "RecipeId: 411853, Name: Delicious Pesto Cream Sauce, Similarity: 0.6742843301587211\n",
            "RecipeId: 337285, Name: Linguine Alla Vongole, Similarity: 0.6705833703062491\n",
            "RecipeId: 172511, Name: Egg Noodles With Brown Butter and Feta, Similarity: 0.6638602458848739\n",
            "RecipeId: 389387, Name: Greek Scampi Pasta, Similarity: 0.6636203828010792\n",
            "RecipeId: 113017, Name: Elswet's Shrimp Pasta in Herb Butter Sauce, Similarity: 0.6614039850047125\n",
            "RecipeId: 361293, Name: Italian Skillet, Similarity: 0.6583478419295449\n",
            "RecipeId: 201796, Name: Pasta With Cherry-Tomatoes and Goat Cheese, Similarity: 0.6566251250582096\n",
            "RecipeId: 338464, Name: Spaghetti Alla Carlofortina (Spaghetti With Fresh Tuna, Cream Of, Similarity: 0.6560931023847619\n",
            "RecipeId: 244216, Name: Bow Tie Pasta With Sun-Dried Tomatoes and Kalamata Olives, Similarity: 0.6550767011704335\n",
            "RecipeId: 501436, Name: Greek Pasta With Meatballs, Similarity: 0.6505584521078558\n",
            "RecipeId: 312390, Name: Rigatoni With Tomato, Eggplant, &amp; Red Peppers, Similarity: 0.6456224975284106\n",
            "RecipeId: 170211, Name: Savory Summer Pasta Salad, Similarity: 0.6453311117786806\n",
            "RecipeId: 365640, Name: Pastiera (Easter Pie), Similarity: 0.638151055922227\n",
            "RecipeId: 101276, Name: Old Town Eggs Derelict, Similarity: 0.6282385489076818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from pymongo import MongoClient\n",
        "from textblob import TextBlob\n",
        "import pickle\n",
        "\n",
        "# MongoDB client setup\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\n",
        "\n",
        "# Load pre-trained model for generating query embeddings\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Load TF-IDF scores for query expansion\n",
        "with open('/content/drive/MyDrive/idf_values.pkl', 'rb') as file:\n",
        "    tfidf_scores = pickle.load(file)\n",
        "\n",
        "# Function for spell correction\n",
        "def spell_correct(query):\n",
        "    corrected_query = str(TextBlob(query).correct())\n",
        "    return corrected_query\n",
        "\n",
        "# Search function using cosine similarity\n",
        "def search_with_cosine_similarity(query_embedding, top_n=10):\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    if not docs:\n",
        "        return []\n",
        "\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        results.append({\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Search function using Nearest Neighbors\n",
        "def search_with_nearest_neighbors(query_embedding, top_n=10):\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    if not docs:\n",
        "        return []\n",
        "\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    neigh = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
        "    neigh.fit(doc_embeddings)\n",
        "    distances, indices = neigh.kneighbors([query_embedding], n_neighbors=top_n)\n",
        "\n",
        "    results = []\n",
        "    for idx, distance in zip(indices[0], distances[0]):\n",
        "        results.append({\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': 1 - distance\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Search function for PDF files using cosine similarity\n",
        "def search_pdf(query):\n",
        "    # Set up MongoDB client\n",
        "    client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "    db = client['searchEngine']\n",
        "    collection = db['pdf_files']\n",
        "\n",
        "    # Create embedding for the search query\n",
        "    query_embedding = model.encode([query])[0]\n",
        "\n",
        "    # Retrieve all stored PDF embeddings from MongoDB\n",
        "    pdf_data = list(collection.find({}))\n",
        "    pdf_embeddings = [np.array(pdf['embedding']) for pdf in pdf_data]\n",
        "\n",
        "    # Calculate cosine similarities between query and stored embeddings\n",
        "    similarities = cosine_similarity([query_embedding], pdf_embeddings)[0]\n",
        "\n",
        "    # Get the indices of the top ten highest similarity scores\n",
        "    top_indices = np.argsort(similarities)[-10:][::-1]\n",
        "\n",
        "    # Collect the names and download links of the top ten PDFs\n",
        "    top_pdfs = []\n",
        "    for index in top_indices:\n",
        "        top_pdfs.append({\n",
        "            'name': pdf_data[index]['file_name'],  # Assuming 'file_name' field exists in your PDF data\n",
        "            'download_link': pdf_data[index]['download_link']\n",
        "        })\n",
        "\n",
        "    return top_pdfs\n",
        "\n",
        "\n",
        "# Search function using clusters\n",
        "def search_using_clusters(query, top_n=10):\n",
        "    # Encode the query to get its vector representation\n",
        "    query_embedding = model.encode([query])[0]\n",
        "\n",
        "    # Retrieve documents with encoded_vector and cluster from the collection\n",
        "    documents = list(collection.find({}, {\"encoded_vector\": 1, \"cluster\": 1}))\n",
        "\n",
        "    # Create numpy arrays for document embeddings and clusters\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in documents])\n",
        "    clusters = np.array([int(doc['cluster']) for doc in documents])\n",
        "\n",
        "    # Calculate cosine similarities between the query and document embeddings\n",
        "    cluster_distances = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "\n",
        "    # Determine the closest cluster based on the max similarity\n",
        "    closest_cluster = clusters[np.argmax(cluster_distances)]\n",
        "\n",
        "    # Retrieve documents from the closest cluster\n",
        "    filtered_docs = list(collection.find({\"cluster\": int(closest_cluster)}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "\n",
        "    # Create numpy arrays for the filtered document embeddings and IDs\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in filtered_docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in filtered_docs]\n",
        "    doc_names = [doc['Name'] for doc in filtered_docs]\n",
        "\n",
        "    # Calculate similarities for the top N results\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    # Collect and return results\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        results.append({\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Combined search and ranking function\n",
        "def search_and_rank(query, top_n=20):\n",
        "    # Step 1: Encode the original query\n",
        "    original_query_embedding = model.encode([query])[0]\n",
        "\n",
        "    # Step 2: Perform normal search with cosine similarity and nearest neighbors\n",
        "    cosine_results = search_with_cosine_similarity(original_query_embedding, top_n)\n",
        "    nn_results = search_with_nearest_neighbors(original_query_embedding, top_n)\n",
        "\n",
        "    # Merge both result sets (union of results)\n",
        "    all_results = {result['RecipeId']: result for result in cosine_results + nn_results}\n",
        "\n",
        "    # Step 3: Apply spell check\n",
        "    corrected_query = spell_correct(query)\n",
        "\n",
        "    # Step 4: Encode the corrected query\n",
        "    corrected_query_embedding = model.encode([corrected_query])[0]\n",
        "\n",
        "    # Step 5: Perform search with the corrected query\n",
        "    corrected_cosine_results = search_with_cosine_similarity(corrected_query_embedding, top_n)\n",
        "    corrected_nn_results = search_with_nearest_neighbors(corrected_query_embedding, top_n)\n",
        "\n",
        "    # Merge expanded results with original results\n",
        "    expanded_results = {result['RecipeId']: result for result in corrected_cosine_results + corrected_nn_results}\n",
        "    all_results.update(expanded_results)\n",
        "\n",
        "    # Step 6: Sort results by cosine similarity (or combined similarity)\n",
        "    sorted_results = sorted(all_results.values(), key=lambda x: x['Similarity'], reverse=True)\n",
        "\n",
        "    # Return top results\n",
        "    return sorted_results[:top_n]\n",
        "\n",
        "# Example usage: Searching for recipes\n",
        "query = \"Italian pasta with pancetta and eggs\"\n",
        "top_ten_results = search_and_rank(query)\n",
        "\n",
        "# Display the results\n",
        "for result in top_ten_results:\n",
        "    print(f\"RecipeId: {result['RecipeId']}, Name: {result['Name']}, Similarity: {result['Similarity']}\")\n",
        "\n",
        "# Example usage: Searching for PDFs\n",
        "pdf_query = \"Quick and easy recipes\"\n",
        "top_ten_pdfs = search_pdf(pdf_query)\n",
        "\n",
        "# Display the PDF results\n",
        "for pdf in top_ten_pdfs:\n",
        "    print(f\"Name: {pdf['name']}, Download Link: {pdf['download_link']}\")\n",
        "\n",
        "# Example usage: Searching within clusters\n",
        "cluster_query = \"Healthy breakfast recipes\"\n",
        "cluster_results = search_using_clusters(cluster_query)\n",
        "\n",
        "# Display the clustered search results\n",
        "for result in cluster_results:\n",
        "    print(f\"RecipeId: {result['RecipeId']}, Name: {result['Name']}, Similarity: {result['Similarity']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcMzRsMMb979",
        "outputId": "842e32c3-ed67-45fd-da0f-448ce1c61e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecipeId: 269099, Name: Wattleseed Pasta, Similarity: 0.7202330125259581\n",
            "RecipeId: 176435, Name: Pasta Puttanesca ( the Madame's Pasta ), Similarity: 0.7100361742691912\n",
            "RecipeId: 203999, Name: Drunken Tuscan Pasta, Similarity: 0.6921510305001513\n",
            "RecipeId: 275554, Name: Pasta With Chicken and Squash, Similarity: 0.6903238633746664\n",
            "RecipeId: 120095, Name: Mizithra Browned Buttered Pasta, Similarity: 0.6868085141883233\n",
            "RecipeId: 379868, Name: Roasted Tomato and Shrimp Pasta, Similarity: 0.6799918370189806\n",
            "RecipeId: 411853, Name: Delicious Pesto Cream Sauce, Similarity: 0.6742843301587211\n",
            "RecipeId: 337285, Name: Linguine Alla Vongole, Similarity: 0.6705833703062491\n",
            "RecipeId: 172511, Name: Egg Noodles With Brown Butter and Feta, Similarity: 0.6638602458848739\n",
            "RecipeId: 389387, Name: Greek Scampi Pasta, Similarity: 0.6636203828010792\n",
            "RecipeId: 113017, Name: Elswet's Shrimp Pasta in Herb Butter Sauce, Similarity: 0.6614039850047125\n",
            "RecipeId: 361293, Name: Italian Skillet, Similarity: 0.6583478419295449\n",
            "RecipeId: 201796, Name: Pasta With Cherry-Tomatoes and Goat Cheese, Similarity: 0.6566251250582096\n",
            "RecipeId: 338464, Name: Spaghetti Alla Carlofortina (Spaghetti With Fresh Tuna, Cream Of, Similarity: 0.6560931023847619\n",
            "RecipeId: 244216, Name: Bow Tie Pasta With Sun-Dried Tomatoes and Kalamata Olives, Similarity: 0.6550767011704335\n",
            "RecipeId: 501436, Name: Greek Pasta With Meatballs, Similarity: 0.6505584521078558\n",
            "RecipeId: 312390, Name: Rigatoni With Tomato, Eggplant, &amp; Red Peppers, Similarity: 0.6456224975284106\n",
            "RecipeId: 170211, Name: Savory Summer Pasta Salad, Similarity: 0.6453311117786806\n",
            "RecipeId: 365640, Name: Pastiera (Easter Pie), Similarity: 0.638151055922227\n",
            "RecipeId: 101276, Name: Old Town Eggs Derelict, Similarity: 0.6282385489076818\n",
            "Name: Easy_recipes.pdf, Download Link: https://drive.google.com/uc?id=1dZA-OVeYW-8aYT30a6UHoXATyUdiShNP\n",
            "RecipeId: 273001, Name: Change of Pace Breakfast or Dessert, Similarity: 0.7126593582351235\n",
            "RecipeId: 379149, Name: Nutritional Breakfast Health Bars, Similarity: 0.6754146340802285\n",
            "RecipeId: 322022, Name: Smart Bars, Similarity: 0.6723231123776015\n",
            "RecipeId: 504825, Name: Matt's Hearty Oatmeal, Similarity: 0.6265187827736329\n",
            "RecipeId: 168645, Name: Pancakes for Two, Similarity: 0.6183213037803096\n",
            "RecipeId: 349987, Name: Whole Grain Blueberry Waffles, Similarity: 0.6042188105252395\n",
            "RecipeId: 58021, Name: Red, (Egg) White, and Blue Omelette, Similarity: 0.5975283004162828\n",
            "RecipeId: 153086, Name: Berry Good Yogurt Parfait, Similarity: 0.5961537728930217\n",
            "RecipeId: 506692, Name: Mixed Berry Breakfast Parfait, Similarity: 0.5911906769533369\n",
            "RecipeId: 151388, Name: Strawberry Yogurt Muffins, Similarity: 0.5833605235944153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pymongo import MongoClient\n",
        "from textblob import TextBlob\n",
        "import pickle\n",
        "\n",
        "# MongoDB client setup\n",
        "client = MongoClient(\"mongodb+srv://Haran:NGjWcKG55e3K83SB@cluster0.0ttlk.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"searchEngine\"]\n",
        "collection = db[\"Recipe\"]\n",
        "\n",
        "# Load pre-trained model for generating query embeddings\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Load TF-IDF scores for query expansion (Optional, adjust path if needed)\n",
        "with open('/content/drive/MyDrive/idf_values.pkl', 'rb') as file:\n",
        "    tfidf_scores = pickle.load(file)\n",
        "\n",
        "# Function for spell correction\n",
        "def spell_correct(query):\n",
        "    return str(TextBlob(query).correct())\n",
        "\n",
        "# Search function using cosine similarity\n",
        "def search_with_cosine_similarity(query_embedding, top_n=10):\n",
        "    docs = list(collection.find({}, {\"RecipeId\": 1, \"Name\": 1, \"encoded_vector\": 1}))\n",
        "    if not docs:\n",
        "        return []\n",
        "\n",
        "    doc_embeddings = np.array([doc['encoded_vector'] for doc in docs])\n",
        "    doc_ids = [doc['RecipeId'] for doc in docs]\n",
        "    doc_names = [doc['Name'] for doc in docs]\n",
        "\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    top_n_indices = similarities.argsort()[::-1][:top_n]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_n_indices:\n",
        "        results.append({\n",
        "            'RecipeId': doc_ids[idx],\n",
        "            'Name': doc_names[idx],\n",
        "            'Similarity': similarities[idx]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Combined search and ranking function\n",
        "def search_and_rank(query, top_n=20):\n",
        "    # Step 1: Encode the original query\n",
        "    original_query_embedding = model.encode([query])[0]\n",
        "\n",
        "    # Step 2: Perform normal search with cosine similarity\n",
        "    cosine_results = search_with_cosine_similarity(original_query_embedding, top_n)\n",
        "\n",
        "    # Step 3: Apply spell check and re-search\n",
        "    corrected_query = spell_correct(query)\n",
        "    corrected_query_embedding = model.encode([corrected_query])[0]\n",
        "    corrected_cosine_results = search_with_cosine_similarity(corrected_query_embedding, top_n)\n",
        "\n",
        "    # Combine results and sort\n",
        "    all_results = {result['RecipeId']: result for result in cosine_results + corrected_cosine_results}\n",
        "    sorted_results = sorted(all_results.values(), key=lambda x: x['Similarity'], reverse=True)\n",
        "\n",
        "    return sorted_results[:top_n]\n",
        "\n",
        "# Frontend - Streamlit\n",
        "# Set up background image and custom styling\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "    .stApp {\n",
        "        background-image: url(\"https://i.pinimg.com/564x/e1/44/f3/e144f36783c75725fb0f2625c6bcd7c8.jpg\");\n",
        "        background-size: cover;\n",
        "        color: #F5F5F5;\n",
        "    }\n",
        "    .stButton>button {\n",
        "        color: white;\n",
        "        background-color: #ff6347;\n",
        "        border-radius: 12px;\n",
        "        padding: 12px;\n",
        "        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.2);\n",
        "        transition: background-color 0.3s ease;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background-color: #ff4500;\n",
        "    }\n",
        "    .stTextInput>div>div>input {\n",
        "        border-radius: 30px;\n",
        "        padding: 10px 40px;\n",
        "        color: #ffffff;\n",
        "    }\n",
        "    .stTextInput>div>div>input::placeholder {\n",
        "        color:  #d7dbdd;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "# Sidebar for filters\n",
        "st.sidebar.header(\"Customize Your Search\")\n",
        "st.sidebar.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "time_filter = st.sidebar.slider(\" Maximum Cooking Time (minutes)\", min_value=1, max_value=120, value=60)\n",
        "st.sidebar.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "rating_filter = st.sidebar.slider(\" Minimum Recipe Rating\", min_value=0.0, max_value=5.0, value=4.0, step=0.1)\n",
        "\n",
        "# Main section - Logo and Title\n",
        "st.markdown('<img src=\"https://i.pinimg.com/564x/e1/44/f3/e144f36783c75725fb0f2625c6bcd7c8.jpg\" class=\"logo\">', unsafe_allow_html=True)\n",
        "st.markdown('<h1 class=\"title\">CookBook Recipe Search Engine</h1>', unsafe_allow_html=True)\n",
        "\n",
        "# Search bar\n",
        "search_query = st.text_input(\n",
        "    \"\",\n",
        "    placeholder=\"Enter recipe name or ingredient\",\n",
        "    key=\"search\",\n",
        "    label_visibility=\"collapsed\"\n",
        ")\n",
        "\n",
        "# Backend integration for searching\n",
        "if search_query:\n",
        "    top_ten_results = search_and_rank(search_query)\n",
        "\n",
        "    if top_ten_results:\n",
        "        st.subheader(\" Search Results\")\n",
        "        for recipe in top_ten_results:\n",
        "            st.write(f\"**{recipe['Name']}** - Similarity: {recipe['Similarity']:.2f}\")\n",
        "            st.button(\" Save Recipe\", key=recipe['RecipeId'])\n",
        "    else:\n",
        "        st.write(\" No recipes found matching your search.\")\n",
        "\n",
        "# Footer with inspirational message\n",
        "st.write(\"---\")\n",
        "st.markdown('<div style=\"text-align: center;\"> Find recipes that match your taste, dietary preferences, and cooking time! </div>', unsafe_allow_html=True)\n"
      ],
      "metadata": {
        "id": "igmxjD3kf5kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\"_id\":{\"$oid\":\"66f9af327bb0b63a28431423\"},\"RecipeId\":{\"$numberInt\":\"373686\"},\"Name\":\"Picnic Cowboy Caviar\",\"AuthorId\":{\"$numberInt\":\"798690\"},\"AuthorName\":\"Amy BC\",\"CookTime\":\"PT1H\",\"PrepTime\":\"PT20M\",\"TotalTime\":\"PT1H20M\",\"DatePublished\":\"2009-05-22T02:13:00Z\",\"Description\":\"Make and share this Picnic Cowboy Caviar recipe from Food.com.\",\"Images\":\"character(0)\",\"RecipeCategory\":\"Black Beans\",\"Keywords\":\"c(\\\"Beans\\\", \\\"Tex Mex\\\", \\\"Southwestern U.S.\\\", \\\"Potluck\\\", \\\"Spring\\\", \\\"Summer\\\", \\\"No Cook\\\", \\\"Refrigerator\\\", \\\"< 4 Hours\\\", \\\"Easy\\\", \\\"Inexpensive\\\")\",\"RecipeIngredientQuantities\":\"c(\\\"15\\\", \\\"15\\\", \\\"15\\\", \\\"5 -6\\\", \\\"1\\\", \\\"1\\\", \\\"2\\\", \\\"2\\\", \\\"1\\\", \\\"1/3\\\", \\\"1/3\\\", \\\"1 1/2\\\", \\\"1/2\\\", \\\"2\\\", \\\"2\\\")\",\"RecipeIngredientParts\":\"c(\\\"black beans\\\", \\\"black-eyed peas\\\", \\\"white corn\\\", \\\"roma tomatoes\\\", \\\"bell pepper\\\", \\\"red onion\\\", \\\"avocados\\\", \\\"cilantro leaf\\\", \\\"red wine vinegar\\\", \\\"extra virgin olive oil\\\", \\\"salt\\\", \\\"pepper\\\", \\\"cumin\\\", \\\"garlic\\\")\",\"AggregatedRating\":{\"$numberDouble\":\"4.0\"},\"ReviewCount\":{\"$numberDouble\":\"1.0\"},\"Calories\":{\"$numberDouble\":\"341.5\"},\"FatContent\":{\"$numberDouble\":\"18.0\"},\"SaturatedFatContent\":{\"$numberDouble\":\"2.6\"},\"CholesterolContent\":{\"$numberDouble\":\"0.0\"},\"SodiumContent\":{\"$numberDouble\":\"612.9\"},\"CarbohydrateContent\":{\"$numberDouble\":\"39.3\"},\"FiberContent\":{\"$numberDouble\":\"12.3\"},\"SugarContent\":{\"$numberDouble\":\"4.1\"},\"ProteinContent\":{\"$numberDouble\":\"11.0\"},\"RecipeServings\":{\"$numberDouble\":\"8.0\"},\"RecipeYield\":{\"$numberDouble\":\"NaN\"},\"RecipeInstructions\":\"c(\\\"Mix the dressing ingredients together.\\\", \\\"Toss dressing with the rest of the ingredients. If you are making this ahead of time toss the avocado with lemon juice before adding it to the rest to avoid browning. Chill at least 1 hour.\\\")\",\"text\":\"picnic cowboy caviar make and share this picnic cowboy caviar recipe from foodcom cbeans tex mex southwestern us potluck spring summer no cook refrigerator 4 hours easy inexpensive black beans cblack beans blackeyed peas white corn roma tomatoes bell pepper red onion avocados cilantro leaf red wine vinegar extra virgin olive oil salt pepper cumin garlic\",\"encoded_vector\":[{\"$numberDouble\":\"-0.12993240356445312\"}],\"cluster\":{\"$numberInt\":\"9\"}}"
      ],
      "metadata": {
        "id": "UmJWv-bYWkW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}