


import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import heapq


from google.colab import drive
drive.mount('/content/drive')


file_path = '/content/drive/MyDrive/datasets/recipes.csv'


df=pd.read_csv(file_path)


df.head()


df.info()


def clean_text(text):
    text = str(text).lower()  # Convert to lowercase
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text


df['Name'] = df['Name'].apply(clean_text)
df['Description'] = df['Description'].apply(clean_text)
df['Keywords'] = df['Keywords'].apply(clean_text)
df['RecipeCategory'] = df['RecipeCategory'].apply(clean_text)
df['RecipeIngredientParts'] = df['RecipeIngredientParts'].apply(clean_text)


df.head()


df['text'] = df['Name'] + ' ' + df['Description'] + ' ' + df['Keywords'] + ' ' + df['RecipeCategory'] + ' ' + df['RecipeIngredientParts']


df.head()


df.dropna(subset=['text'], inplace=True)


# Initialize TF-IDF Vectorizer and transform dataset
vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform(df['text'])

# Get idf values for pruning low-idf terms
idf_values = dict(zip(vectorizer.get_feature_names_out(), vectorizer.idf_))



# Function to prune low-idf terms from a query
def prune_query(query, threshold=1.5):
    terms = query.split()
    # Retain only terms with high idf values
    pruned_terms = [term for term in terms if idf_values.get(term, 0) >= threshold]
    return ' '.join(pruned_terms)


# Function to compute top-K cosine similarities using a heap
def efficient_top_k_cosine(query_vec, top_k=5):
    cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()

    # Use heapq to find the top K cosine scores
    top_indices = heapq.nlargest(top_k, range(len(cosine_similarities)), key=cosine_similarities.__getitem__)
    return top_indices


def search_recipes(query, top_k=5):
    # Clean and prune the query using high-idf terms
    query = clean_text(query)
    query = prune_query(query)

    if not query:
        return pd.DataFrame(columns=['Name', 'Description', 'Keywords', 'RecipeCategory', 'RecipeIngredientParts' ])  # Return empty if the query has no high-idf terms

    # Convert the query into a TF-IDF vector
    query_vec = vectorizer.transform([query])

    # Efficient top-K cosine ranking using heap
    top_indices = efficient_top_k_cosine(query_vec, top_k)

    # Return the most similar recipes
    return df.iloc[top_indices][['Name', 'Description', 'Keywords', 'RecipeCategory', 'RecipeIngredientParts' ]].reset_index(drop=True)



query = "cheesecake"
results = search_recipes(query)
print(results)





!pip install sentence_transformers


from sentence_transformers import SentenceTransformer
import spacy


# Load the English NLP model for NER using SpaCy
nlp = spacy.load('en_core_web_sm')

# Load the pre-trained model for semantic search (Sentence-BERT)
sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')


'''
def extract_entities(text):
    doc = nlp(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities
    '''


#df['entities'] = df['text'].apply(extract_entities)


e_file_path = '/content/drive/MyDrive/datasets/entitled_df.csv'


e_df=pd.read_csv(e_file_path)


e_df.head()


def query_expansion(query):
    # Implement expansion techniques here (Word2Vec, GloVe, etc.)
    # For now, we'll return the original query as it is
    return query


def encode_documents(documents):
    return sbert_model.encode(documents)


import numpy as np


doc_embeddings= np.load("/content/drive/MyDrive/datasets/doc_embeddings.npy")


query = "ramen"
cleaned_query = clean_text(query)
expanded_query = query_expansion(cleaned_query)

query_embedding = sbert_model.encode([expanded_query])
similarity_scores = cosine_similarity(query_embedding, doc_embeddings)

top_n = 5
top_indices = similarity_scores[0].argsort()[-top_n:][::-1]

# Display the top similar recipes
print("Query:", query)
print("\nTop 5 similar recipes:\n")
for idx in top_indices:
    print(f"Recipe Name: {e_df.iloc[idx]['Name']}")
    print(f"Author: {e_df.iloc[idx]['AuthorName']}")
    print(f"Cook Time: {e_df.iloc[idx]['CookTime']} | Prep Time: {df.iloc[idx]['PrepTime']} | Total Time: {df.iloc[idx]['TotalTime']}")
    print(f"Date Published: {e_df.iloc[idx]['DatePublished']}")
    print(f"Description: {e_df.iloc[idx]['Description']}")
    print(f"Cholesterol: {e_df.iloc[idx]['CholesterolContent']}, Sodium: {df.iloc[idx]['SodiumContent']}, Protein: {df.iloc[idx]['ProteinContent']}")
    print(f"Entities: {e_df.iloc[idx]['entities']}")
    print(f"Similarity Score: {similarity_scores[0][idx]}")
    print("\n---\n")


model_path=('/content/drive/MyDrive/datasets/recipe_word2vec.pkl')
